{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`max_tokens`:** limita o tamanho do output do modelo\n",
    "---\n",
    "\n",
    "- **`temperature` baixa (próxima de 0)**:\n",
    "  - O modelo será mais **determinístico** e **conservador**. Ele tenderá a escolher palavras com maior probabilidade, gerando respostas mais previsíveis e consistentes.\n",
    "  - Exemplos:\n",
    "    - Uma `temperature` de 0 ou próxima de 0 resultará em respostas bem focadas e diretas, com menos variação.\n",
    "\n",
    "- **`temperature` alta (próxima de 1)**:\n",
    "  - O modelo será mais **aleatório** e **criativo**. Ele terá maior propensão a explorar opções menos prováveis, resultando em respostas mais variadas e inesperadas.\n",
    "  - Exemplos:\n",
    "    - Uma `temperature` de 1 ou próxima disso resultará em respostas mais criativas ou \"livres\", com mais variação na escolha de palavras e estrutura.\n",
    "\n",
    "- **`temperature` acima de 1**:\n",
    "  - Valores maiores que 1 podem resultar em respostas ainda mais diversas, mas também mais erráticas e menos coerentes.\n",
    "\n",
    " \n",
    " #\n",
    "- **`temperature` baixa (0-0.3)**: Respostas mais focadas, diretas e consistentes.\n",
    "- **`temperature` média (0.4-0.7)**: Equilíbrio entre consistência e criatividade.\n",
    "- **`temperature` alta (0.8-1)**: Respostas mais criativas, diversificadas e imprevisíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myChat = [\n",
    "    {'role': 'user', 'content': 'faça uma piada curta'}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages = myChat,\n",
    "    model =  'gpt-3.5-turbo-0125',\n",
    "    max_tokens = 500,\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controle de gastos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=23, prompt_tokens=14, total_tokens=37, prompt_tokens_details={'cached_tokens': 0}, completion_tokens_details={'reasoning_tokens': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transdorma a mensagem já para o formato de dicionário, aí basta fazer o append no chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Por que o livro de matemática ficou de castigo? Porque ele só fazia problemas.',\n",
       " 'role': 'assistant',\n",
       " 'function_call': None,\n",
       " 'tool_calls': None,\n",
       " 'refusal': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Por que o livro de matemática ficou de castigo? Porque ele só fazia problemas.',\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.model_dump(exclude_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
